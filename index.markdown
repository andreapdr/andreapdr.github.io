---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default 
---
# Hello World

<style>

img {width: 30%;float:right;}

</style>

<img src="/imgs/andrea_blog.png" alt="some years have passed, though">

Hi ðŸ‘‹ My name is Andrea Pedrotti and I am currently a Post-Doc at the `Institute of Information Science and Technologies` of the `National Council of Research` (ISTI-CNR). Here, I am a member of the <a href="https://hlt-isti.github.io/">AI4Text Group</a> in the `Artificial Intelligence for Media and Humanities laboratory`. I have obtained my PhD in Computer Science from the `University of Pisa`, with the thesis `Heterogeneous Transfer Learning in Natural Language Processing`.

My primary interests lie in  representation learning, both at large and small scale, with a particular interests in `heterogeneous transfer learning`, I like playing with different domains such as languages and perceptual modalities within `multimodal` and `multilingual` settings.

I have received my master's degree in Digital Humanities at the University of Pisa with a thesis on `Cross-Lingual Text-Classification`, supervised by Dr. Fabrizio Sebastiani and Dr. Alejandro Moreo.

During 2022, I have spent a few months at the <a href="https://www.cl.uni-heidelberg.de/nlpgroup/">HD NLP Group</a> of `Heidelberg University` under the supervision of Prof. Dr. Anette Frank working on the assessment of Video-and-Language Models.

In 2023, I have visited the <a href="https://ltl.mmll.cam.ac.uk/">Language Technology Lab</a> at `Cambridge University`, where I have worked on the interplay between multi-language and multi-modal models together with Dr. Ivan VuliÄ‡.

For any question, feel free to drop me an email at <a class="u-email" href="mailto:{{ site.email2 }}">`{{ site.email2 }}`</a> ðŸ™ƒ


# Publications

* <a href="https://andreapdr.github.io/">`How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian`</a> **Andrea Pedrotti**, Giulia Rambelli, Caterina Villani, and Marianna Bolognesi. 2025. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025).

* <a href="https://andreapdr.github.io/">`Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors`</a> **Andrea Pedrotti**, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell'Orletta, and Andrea Esuli. 2025. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025).

* <a href="https://arxiv.org/abs/2311.07022">`ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models`</a> Ilker Kesen, **Andrea Pedrotti**, Moustafa Dogan et al. 2023. In Proceedings of the 12th International Conference on Learning Representations (ICLR 2024)

* <a href="https://doi.org/10.1145/3544104">`Generalized Funnelling: Ensemble Learning and Heterogeneous Document Embeddings for Cross-Lingual Text Classification.`</a> Alejandro Moreo, **Andrea Pedrotti**, and Fabrizio Sebastiani. 2022. ACM Transactions on Information Systems 41 (TOIS)

* <a href="https://doi.org/10.1145/3412841.3442093">`Heterogeneous Document Embeddings for Cross-Lingual Text Classification`</a> Alejandro Moreo, **Andrea Pedrotti**, and Fabrizio Sebastiani. 2021. In Proceedings of the 36th Annual ACM Symposium on Applied Computing (SAC 2021)

# Talks & Seminars

<a href="https://www.cnr.it/it/eventi/allegato/13756">`First CNR-DFKI workshop on AI Technologies`</a> where I have represented the `AI4Text` group talking about our current research directions and discussed the future scenarios of the NLP field.

<a href="https://talks.cam.ac.uk/talk/index/207655">`Seminar Series Cambridge`</a>, "ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"

<a href="https://www.cl.uni-heidelberg.de/colloquium/cl_colloquium/">`Colloquium Talk Heidelberg`</a>, "Whatâ€™s In An Action? A benchmark for Video-and-Language models through the lens
of change-of-state verbs"
